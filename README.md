# *HyperMind: Empirical Evidence-Based Hyperparameter Optimization via RAG-Enhanced LLMs*

### - Project Overview
The problem with traditional hyperparameter optimization methods is that they rely on random or grid search approaches, which are inefficient and fail to leverage the vast knowledge accumulated in the machine learning community. We developed a system that proactively predicts optimal hyperparameter configurations by utilizing Retrieval-Augmented Generation and Large Language Models to provide evidence-based recommendations to users. We aimed to develop a system that could efficiently analyze training patterns and automatically suggest optimal hyperparameters based on empirical evidence and domain expertise.
![image](https://github.com/user-attachments/assets/f5c8298d-67d2-4a29-a450-7108f781983e)

### - Project Description
The project begins by first analyzing learning curves, model architectures, and dataset characteristics to make initial assessments. Based on this initial analysis, the RAG system retrieves relevant knowledge from research papers and best practices as the next step.
Even in cases where standard optimization techniques would typically suggest suboptimal parameters, better configurations may still be discovered through intelligent evidence-based search and expert knowledge integration. Therefore, the system does not immediately provide a single "optimal" configuration. Instead, it is designed to present comprehensive analysis and multiple viable options at the end of the process, enabling users to make informed decisions with all relevant factors considered.

![image](https://github.com/user-attachments/assets/61a2ec67-c233-40dc-8460-62950367b7cc)


### - Contributing & Contact

- minju 
  - 이메일: [smj0324@hanyang.ac.kr](mailto:smj0324@hanyang.ac.kr)

- heymin
  - 이메일: [phm0707@hanyang.ac.kr](mailto:phm0707@hanyang.ac.kr)

- seung-gyeom
  - 이메일: [skkim3533@hanyang.ac.kr](mailto:skkim3533@hanyang.ac.kr)
